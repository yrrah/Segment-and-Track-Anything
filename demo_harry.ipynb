{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import cv2\n",
    "from SegTracker import SegTracker\n",
    "from model_args import aot_args,sam_args,segtracker_args\n",
    "from PIL import Image\n",
    "from aot_tracker import _palette\n",
    "import numpy as np\n",
    "import torch\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_dilation\n",
    "import gc\n",
    "def save_prediction(pred_mask,output_dir,file_name):\n",
    "    save_mask = Image.fromarray(pred_mask.astype(np.uint8))\n",
    "    save_mask = save_mask.convert(mode='P')\n",
    "    save_mask.putpalette(_palette)\n",
    "    save_mask.save(os.path.join(output_dir,file_name))\n",
    "def colorize_mask(pred_mask):\n",
    "    save_mask = Image.fromarray(pred_mask.astype(np.uint8))\n",
    "    save_mask = save_mask.convert(mode='P')\n",
    "    save_mask.putpalette(_palette)\n",
    "    save_mask = save_mask.convert(mode='RGB')\n",
    "    return np.array(save_mask)\n",
    "def draw_mask(img, mask, alpha=0.5, id_countour=False):\n",
    "    img_mask = np.zeros_like(img)\n",
    "    img_mask = img\n",
    "    if id_countour:\n",
    "        # very slow ~ 1s per image\n",
    "        obj_ids = np.unique(mask)\n",
    "        obj_ids = obj_ids[obj_ids!=0]\n",
    "\n",
    "        for id in obj_ids:\n",
    "            # Overlay color on  binary mask\n",
    "            if id <= 255:\n",
    "                color = _palette[id*3:id*3+3]\n",
    "            else:\n",
    "                color = [0,0,0]\n",
    "            foreground = img * (1-alpha) + np.ones_like(img) * alpha * np.array(color)\n",
    "            binary_mask = (mask == id)\n",
    "\n",
    "            # Compose image\n",
    "            img_mask[binary_mask] = foreground[binary_mask]\n",
    "\n",
    "            countours = binary_dilation(binary_mask,iterations=1) ^ binary_mask\n",
    "            img_mask[countours, :] = 0\n",
    "    else:\n",
    "        binary_mask = (mask!=0)\n",
    "        countours = binary_dilation(binary_mask,iterations=1) ^ binary_mask\n",
    "        foreground = img*(1-alpha)+colorize_mask(mask)*alpha\n",
    "        img_mask[binary_mask] = foreground[binary_mask]\n",
    "        img_mask[countours,:] = 0\n",
    "        \n",
    "    return img_mask.astype(img.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'au_air'\n",
    "io_args = {\n",
    "    'input_video': f'./assets/{video_name}.mp4',\n",
    "    'output_mask_dir': f'./assets/{video_name}_masks', # save pred masks\n",
    "    'output_video': f'./assets/{video_name}_seg.mp4', # mask+frame vizualization, mp4 or avi, else the same as input video\n",
    "    'output_gif': f'./assets/{video_name}_seg.gif', # mask visualization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = \"au_air\"\n",
    "file_path = f'./assets/{file_name}'\n",
    "imgs_path = sorted([os.path.join(file_path, img_name) for img_name in os.listdir(file_path)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning SAM on the First Frame for Good Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mouse_event(event):\n",
    "    x, y = event.xdata, event.ydata\n",
    "    print(x, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread(imgs_path[0])\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(frame)\n",
    "cid = fig.canvas.mpl_connect('button_press_event', mouse_event)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# del segtracker\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_click_mask(image, click_prompt):\n",
    "    # choose good parameters in sam_args based on the first frame segmentation result\n",
    "    # other arguments can be modified in model_args.py\n",
    "    # note the object number limit is 255 by default, which requires < 10GB GPU memory with amp\n",
    "    sam_args['generator_args'] = {\n",
    "            'points_per_side': 30,\n",
    "            'pred_iou_thresh': 0.8,\n",
    "            'stability_score_thresh': 0.9,\n",
    "            'crop_n_layers': 1,\n",
    "            'crop_n_points_downscale_factor': 2,\n",
    "            'min_mask_region_area': 200,\n",
    "        }\n",
    "    segtracker = SegTracker(segtracker_args,sam_args,aot_args)\n",
    "    segtracker.restart_tracker()\n",
    "    frame = cv2.imread(image)\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    seg_mask, masked_frame = segtracker.seg_acc_click( \n",
    "                                                  origin_frame=frame, \n",
    "                                                  coords=np.array(click_prompt[\"points_coord\"]),\n",
    "                                                  modes=np.array(click_prompt[\"points_mode\"]),\n",
    "                                                  multimask=click_prompt[\"multimask\"],\n",
    "                                                )\n",
    "    return seg_mask, masked_frame\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "click_masks = []\n",
    "masked_frames = []\n",
    "\n",
    "seg_mask, masked_frame = get_click_mask(imgs_path[0], click_prompt = {\n",
    "    \"points_coord\":[[1060,500],[1276,464]],\n",
    "    \"points_mode\":[1,0],\n",
    "    \"multimask\":\"True\",\n",
    "})\n",
    "click_masks.append(seg_mask)\n",
    "masked_frames.append(masked_frame)\n",
    "\n",
    "seg_mask, masked_frame = get_click_mask(imgs_path[0], click_prompt = {\n",
    "    \"points_coord\":[[1535,460],[1276,464]],\n",
    "    \"points_mode\":[1,0],\n",
    "    \"multimask\":\"True\",\n",
    "})\n",
    "click_masks.append(seg_mask)\n",
    "masked_frames.append(masked_frame)\n",
    "\n",
    "seg_mask, masked_frame = get_click_mask(imgs_path[6], click_prompt = {\n",
    "    \"points_coord\":[[775,502],[904,490]],\n",
    "    \"points_mode\":[1,0],\n",
    "    \"multimask\":\"True\",\n",
    "})\n",
    "click_masks.append(seg_mask)\n",
    "masked_frames.append(masked_frame)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(masked_frames[0])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Results for the Whole Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For every sam_gap frames, we use SAM to find new objects and add them for tracking\n",
    "# larger sam_gap is faster but may not spot new objects in time\n",
    "segtracker_args = {\n",
    "    'sam_gap': 5, # the interval to run sam to segment new objects\n",
    "    'min_area': 200, # minimal mask area to add a new mask as a new object\n",
    "    'max_obj_num': 255, # maximal object number to track in a video\n",
    "    'min_new_obj_iou': 0.8, # the area of a new object in the background should > 80% \n",
    "}\n",
    "# output masks\n",
    "output_dir = io_args['output_mask_dir']\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "pred_list = []\n",
    "masked_pred_list = []\n",
    "sam_gap = segtracker_args['sam_gap']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def track_frames(start: int, end: int):\n",
    "    with torch.cuda.amp.autocast():\n",
    "        for i in range(start, end):\n",
    "            frame = cv2.imread(imgs_path[i])\n",
    "            frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "            pred_mask = segtracker.track(frame,update_memory=True)\n",
    "            masked_frame = draw_mask(frame,pred_mask)\n",
    "            masked_pred_list.append(masked_frame)\n",
    "            print(\"processed frame {}, obj_num {}\".format(i,segtracker.get_obj_num()),end='\\r')\n",
    "\n",
    "frame = cv2.imread(imgs_path[0])\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "with torch.cuda.amp.autocast():\n",
    "    segtracker = SegTracker(segtracker_args,sam_args,aot_args)\n",
    "    refined_merged_mask = segtracker.add_mask(click_masks[0])\n",
    "    segtracker.update_origin_merged_mask(refined_merged_mask)\n",
    "    segtracker.curr_idx += 1\n",
    "    refined_merged_mask = segtracker.add_mask(click_masks[1])\n",
    "    segtracker.curr_idx += 1\n",
    "    segtracker.update_origin_merged_mask(refined_merged_mask)\n",
    "    segtracker.add_reference(frame, segtracker.origin_merged_mask)\n",
    "    segtracker.first_frame_mask = segtracker.origin_merged_mask\n",
    "\n",
    "    track_frames(0, 6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frame = cv2.imread(imgs_path[6])\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    # seg_mask = segtracker.seg(frame)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    track_mask = segtracker.track(frame)\n",
    "    # find new objects, and update tracker with new objects\n",
    "    new_obj_mask = segtracker.find_new_objs(track_mask, click_masks[2])\n",
    "    pred_mask = track_mask + new_obj_mask\n",
    "    # segtracker.restart_tracker()\n",
    "    segtracker.add_reference(frame, pred_mask, 6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seg_mask = (track_mask==0) * (click_masks[2]*2)\n",
    "new_obj_mask2 = seg_mask\n",
    "new_obj_ids = np.unique(new_obj_mask2)\n",
    "new_obj_ids = new_obj_ids[new_obj_ids!=0]\n",
    "idx = 2\n",
    "new_obj_area = np.sum(new_obj_mask2==idx)\n",
    "obj_area = np.sum(seg_mask==idx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.max(track_mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.axis('off')\n",
    "plt.imshow(draw_mask(frame,pred_mask,id_countour=False))\n",
    "# plt.imshow(frame)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    track_frames(6, 17)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.widgets import Slider\n",
    "\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "img = ax.imshow(masked_pred_list[0], interpolation='nearest')\n",
    "plt.axis('off')\n",
    "\n",
    "axfreq = fig.add_axes([0.25, 0.1, 0.65, 0.03])\n",
    "freq_slider = Slider(\n",
    "    ax=axfreq,\n",
    "    label=\"image\",\n",
    "    valmin=0,\n",
    "    valmax=len(masked_pred_list),\n",
    "    valstep=1,\n",
    "    valinit=0,\n",
    ")                 \n",
    "\n",
    "# The function to be called anytime a slider's value changes\n",
    "def update(val):\n",
    "    img.set_data(masked_pred_list[val])\n",
    "    fig.canvas.draw()\n",
    "\n",
    "freq_slider.on_changed(update)\n",
    "                 \n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ldm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "536611da043600e50719c9460971b5220bad26cd4a87e5994bfd4c9e9e5e7fb0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
